---
title: "E2"
author: "Tae Hyeon Kwon, undergrad(ITM)"
date: '`r Sys.Date()` '
output: pdf_document
---

```{python}
import numpy as np
import pandas as pd

gamma = 1
states = np.arange(0,80,10).astype('str')

P_normal = pd.DataFrame(np.matrix([[0,1,0,0,0,0,0,0],
                                 [0,0,1,0,0,0,0,0],
                                 [0,0,0,1,0,0,0,0],
                                 [0,0,0,0,1,0,0,0],
                                 [0,0,0,0,0,1,0,0],
                                 [0,0,0,0,0,0,1,0],
                                 [0,0,0,0,0,0,0,1],
                                 [0,0,0,0,0,0,0,1]]), index=states, columns=states)

P_speed = pd.DataFrame(np.matrix([[0.1,0,0.9,0,0,0,0,0],
                                 [0.1,0,0,0.9,0,0,0,0],
                                 [0,0.1,0,0,0.9,0,0,0],
                                 [0,0,0.1,0,0,0.9,0,0],
                                 [0,0,0,0.1,0,0,0.9,0],
                                 [0,0,0,0,0.1,0,0,0.9],
                                 [0,0,0,0,0,0.1,0,0.9],
                                 [0,0,0,0,0,0,0,1]]), index=states, columns=states)


def transition (given_pi, states,P_normal, P_speed):
    P_out = pd.DataFrame(np.zeros((len(states),len(states))),index=states, columns= states)

    for s in states:
        action_dist = given_pi.loc[s]
        P = action_dist['normal']*P_normal+action_dist['speed']*P_speed
        P_out.loc[s] = P.loc[s]

    return P_out


R_s_a = pd.DataFrame(np.matrix([-1,-1,-1,-1,0,-1,-1,0,-1.5,-1.5,-1.5,-1.5,-0.5,-1.5,-1.5,0]).reshape(len(states),2,order='F'),columns=['normal','speed'],index=states)

def reward_fn (given_pi, R_s_a):
    R_pi = np.asarray((given_pi*R_s_a).sum(axis=1)).reshape(-1,1)
    return R_pi

def policy_eval (given_pi):
    R = reward_fn(given_pi, R_s_a= R_s_a)
    P = transition(given_pi, states = states, P_normal = P_normal, P_speed = P_speed)

    gamma  = 1
    epsilon = 10**(-8)

    v_old = np.zeros((8, 1))
    v_new = R + np.dot(gamma * P, v_old)



    while np.max(abs(v_new - v_old)) > epsilon:
        v_old = v_new
        v_new = R + np.dot(gamma * P, v_old)

    return v_new

pi_speed = pd.DataFrame(np.c_[np.repeat(0,len(states)),np.repeat(1,len(states))], index = states, columns=
                        ['normal', 'speed'])

a = policy_eval(pi_speed).T

print(a)

pi_50 = pd.DataFrame(np.c_[np.repeat(0.5,len(states)),np.repeat(0.5,len(states))], index = states, columns=
                        ['normal', 'speed'])

b = policy_eval(pi_50).T

print(b)



V_old = policy_eval(pi_speed)
pi_old = pi_speed
q_s_a = R_s_a + np.c_[np.dot(gamma*P_normal,V_old),np.dot(gamma*P_speed,V_old)]

print(q_s_a)

pi_new_vec = q_s_a.idxmax(axis=1)
pi_new = pd.DataFrame(np.zeros(pi_old.shape), index=pi_old.index,columns=pi_old.columns)


for i in range(len(pi_new_vec)):
    pi_new.iloc[i][pi_new_vec[i]]=1

print(pi_new)


def policy_improve(V_old, pi_old = pi_old, R_s_a = R_s_a, gamma = gamma, P_normal = P_normal, P_speed = P_speed):
    q_s_a = R_s_a + np.c_[np.dot(gamma * P_normal, V_old), np.dot(gamma * P_speed, V_old)]

    pi_new_vec = q_s_a.idxmax(axis=1)
    pi_new = pd.DataFrame(np.zeros(pi_old.shape), index=pi_old.index, columns=pi_old.columns)

    for i in range(len(pi_new_vec)):
        pi_new.iloc[i][pi_new_vec[i]] = 1

    return pi_new

pi_old = pi_speed
V_old = policy_eval(pi_old)
pi_new = policy_improve(V_old, pi_old=pi_old, R_s_a=R_s_a, gamma=gamma, P_normal=P_normal, P_speed=P_speed)

print(pi_old)

print(pi_new)

#step 0
pi_old = pi_speed
print(pi_old)

#step 1
V_old = policy_eval(pi_old)
pi_new = policy_improve(V_old, pi_old = pi_old, R_s_a = R_s_a, gamma = gamma, P_normal = P_normal, P_speed = P_speed)
pi_old = pi_new

print(pi_old)

#step 2
V_old = policy_eval(pi_old)
pi_new = policy_improve(V_old, pi_old = pi_old, R_s_a = R_s_a, gamma = gamma, P_normal = P_normal, P_speed = P_speed)
pi_old = pi_new

print(pi_old)

#step 3
V_old = policy_eval(pi_old)
pi_new = policy_improve(V_old, pi_old = pi_old, R_s_a = R_s_a, gamma = gamma, P_normal = P_normal, P_speed = P_speed)
pi_old = pi_new

print(pi_old)

#policy iteration(infinite)
pi_old = pi_speed
cnt = 0
while True :
    print(cnt, "-th iteration")
    print(pi_old.T)
    V_old = policy_eval(pi_old)
    pi_new = policy_improve(V_old, pi_old = pi_old, R_s_a = R_s_a, gamma = gamma, P_normal = P_normal, P_speed = P_speed)
    if pi_new.equals(pi_old)==True:
        break
    pi_old = pi_new
    cnt = cnt+1


print(policy_eval(pi_new))

#policy iteration(50)
pi_old = pi_50
cnt = 0
while True :
    print(cnt, "-th iteration")
    print(pi_old.T)
    V_old = policy_eval(pi_old)
    pi_new = policy_improve(V_old, pi_old = pi_old, R_s_a = R_s_a, gamma = gamma, P_normal = P_normal, P_speed = P_speed)
    if pi_new.equals(pi_old)==True:
        break
    pi_old = pi_new
    cnt = cnt+1


print(policy_eval(pi_new))
```