---
title: "Lecture C2. Discrete Time Markov Chain2 Solution"  
author: "Reinforcement Learning Study"  
date: "`r Sys.Date()`"  
output:   
  pdf_document:  
    latex_engine: xelatex
    highlight: haddock  
    keep_tex: true  
    includes:
      in_header: rmd-pdf-support/latex-topmatter.tex
    # pandoc_args: [
    #  "-V", "classoption=twocolumn"
    # ]
    toc: true   
    toc_depth: 2  
    # number_sections: true  
monofont: Consolas
smaller: yes
classoption: a4paper
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(background = '718CBA')  
```

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
library(reticulate)
#matplotlib <- import("matplotlib")
#matplotlib$use("Agg", force = TRUE)
```

\newpage

## Method 1 -eigen-decomposition p.12 

### in R
```{r,echo = TRUE}
P <- array(c(0.7, 0.5, 0.3, 0.5),dim =c(2,2))
eigen(t(P)) #eigen-decomposition for P^t
```

```{r, echo=TRUE}
x_1 <-eigen(t(P))$vectors[,1]
x_1
```

```{r, echo=TRUE}
v<-x_1/sum(x_1)
v
```
\newpage

### in Python 
```{python, echo=TRUE}
import numpy as np
P = np.array([[0.7, 0.3],[0.5, 0.5]])
egien_value, egien_vector = np.linalg.eig(P.T) #eigen-decomposition for P^t
print("egien_value :\n",egien_value)
print("egien_vector :\n",egien_vector)
```


```{python, echo=TRUE}
x_1=egien_vector[:,0]
print(x_1)
```

```{python, echo,TRUE}
v=x_1/np.sum(x_1)
print(v)
```


\newpage

## Method 2- system of linear equation p.15

### in R 
```{r, echo=TRUE}
P<- array(c(0.7, 0.5, 0.3, 0.5), dim =c(2,2))
n<- nrow(P)
I<-diag(n)
A<-cbind(P-I,rep(1,n))
b<-array(c(rep(0,n),1),dim =c(1, n+1))
A
b
```

```{r, echo=TRUE}
v <- solve(A %*%t(A),A%*%t(b))
v
```

\newpage
### in Python 

```{python, echo=TRUE}
import numpy as np
P=np.array([[0.7, 0.3],[0.5, 0.5]])
n=len(P) # n=|S|
I=np.identity(n) # identity matrix 
A=np.c_[P-I,np.repeat(1,n)] ## np._c_ equalt to cbind in r
b=np.append(np.repeat(0,n), np.array(1))
print(A)
```


```{python, echo=TRUE}
print(b)
```


```{python, echo=TRUE}
v=np.linalg.solve(np.dot(A,A.T),np.dot(A,b.T))
print(v)
```




\newpage

## Limiting Probability -Motivation p.17


### in R
```{r eval=TRUE, warning=FALSE}
library(expm)
P <- array(c(0.7,0.5,0.3,0.5), dim = c(2,2))
P %*% P
P %^% 3
P %^% 4
P %^% 20
```


\newpage
### in Python 

```{python}
import numpy as np
from numpy.linalg import matrix_power

P = np.array([[0.7,0.5],[0.3,0.5]])
print(P)
print(matrix_power(P,2))
print(matrix_power(P,3))
print(matrix_power(P,4))
print(matrix_power(P,20))
```

\newpage


## Limiting Probability- p.19

The limiting distribution may or may not exit. For example 

### in r 

```{r,echo=TRUE}
library(expm)
P<-array(c(1,0,0,1), dim=c(2,2))
P
P %^% 2
P %^% 3
```


\newpage
### in Python
```{python,echo=TRUE}
from numpy.linalg import matrix_power

P=np.array([[0,1],[1,0]])
print(P)
print(matrix_power(P,2))
print(matrix_power(P,3))
```



```{r message=FALSE, warning=FALSE, paged.print=TRUE}
"Done, Lecture C2. Discrete Time Markov Chain2 "
```
