---
title: "F1"  
author: "Reinforcement Learning Study"  
date: "`r Sys.Date()`"  
output:   
  pdf_document:  
    latex_engine: xelatex
    highlight: haddock  
    keep_tex: true  
    includes:
      in_header: rmd-pdf-support/latex-topmatter.tex
    # pandoc_args: [
    #  "-V", "classoption=twocolumn"
    # ]
    toc: true   
    toc_depth: 2  
    # number_sections: true  
monofont: Consolas
smaller: yes
classoption: a4paper
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(background = '718CBA')  
```

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
library(reticulate)
matplotlib <- import("matplotlib")
matplotlib$use("Agg", force = TRUE)
use_virtualenv("r-reticulate")
```
\newpage

## Preperation

```{python,echo=TRUE}
import numpy as np
import pandas as pd 


states=np.arange(0,70+10,10).astype('str')
P_normal=pd.DataFrame(np.matrix([
                    [0,1,0,0,0,0,0,0],
                    [0,0,1,0,0,0,0,0],
                    [0,0,0,1,0,0,0,0],
                    [0,0,0,0,1,0,0,0],
                    [0,0,0,0,0,1,0,0],
                    [0,0,0,0,0,0,1,0],
                    [0,0,0,0,0,0,0,1],
                    [0,0,0,0,0,0,0,1]]), index=states,columns=states)

P_speed=pd.DataFrame(np.matrix([
                   [.1,0,.9,0,0,0,0,0],
                   [.1,0,0,.9,0,0,0,0],
                   [0,.1,0,0,.9,0,0,0],
                   [0,0,.1,0,0,.9,0,0],
                   [0,0,0,.1,0,0,.9,0],
                   [0,0,0,0,.1,0,0,.9],
                   [0,0,0,0,0,.1,0,.9],
                   [0,0,0,0,0,0,0,1]]), index=states, columns=states)

R_s_a=pd.DataFrame(np.matrix([-1,-1,-1,-1,0.0,-1,-1,0,-1.5,-1.5,-1.5,-1.5,-0.5,-1.5,-1.5,0]).reshape(len(states),2,order='F'),columns=['n','s'],index=states)

print("R_s_a:\n",R_s_a.T,"\n")

pi_speed=pd.DataFrame(np.c_[np.repeat(0,len(states)),np.repeat(1,len(states))], index=states, columns=['n','s'])

pi_50=pd.DataFrame(np.c_[np.repeat(0.5,len(states)), np.repeat(0.5,len(states))],index=states, columns=['n','s'])

print("Pi_speed:\n",pi_speed.T,'\n')

print("Pi_50:\n",pi_50.T,'\n')

```

\newpage

## Simulator for Pi_speed

```{python,echo=TRUE}
pi = pi_speed

np.random.seed(1234)
history =[] 
MC_N = 10000

for MC_i in range(MC_N):
    s_now ="0"
    history_i =[s_now]
    
    while(s_now != "70"):
        if np.random.uniform(0,1) < pi.loc[s_now]['n']:
            a_now = "n"
            P = P_normal
        else:
            a_now = "s"
            P = P_speed
    
        r_now = str(R_s_a.loc[s_now][a_now])
        s_next = states[np.argmin(P.loc[s_now].cumsum() < np.random.uniform(0,1))]
        history_i.extend([a_now,r_now,s_next])
        s_now=s_next
        
    history.append(history_i)

history_speed =history
    
history_speed_20 = list(map(lambda x:",".join(x),history_speed[:20] ))

history_speed_20
```

\newpage

### Simulator Pi_50

```{python,echo=TRUE}
pi = pi_50

np.random.seed(1234)
history =[] 
MC_N = 10000

for MC_i in range(MC_N):
    s_now ="0"
    history_i =[s_now]
    
    while(s_now != "70"):
        if np.random.uniform(0,1) < pi.loc[s_now]['n']:
            a_now = "n"
            P = P_normal
        else:
            a_now = "s"
            P = P_speed
    
        r_now = str(R_s_a.loc[s_now][a_now])
        s_next = states[np.argmin(P.loc[s_now].cumsum() < np.random.uniform(0,1))]
        history_i.extend([a_now,r_now,s_next])
        s_now=s_next
        
    history.append(history_i)

history_50 =history
    
history_50_20=list(map(lambda x:",".join(x),history_50[:20] ))
history_pi_50 = list(map(lambda x:",".join(x),history_50))

history_50_20

```

\newpage

## Implementation 1 - pi_speed(vectorized)

```{python,echo=TRUE}
pol_eval= pd.DataFrame(np.zeros(shape=(len(states),2)), index=states, columns=['count','sum'])

pol_eval.T

for MC_i in range(len(history_speed)):
    history_i = history_speed[MC_i]
    
    for j in range(0, len(history_i),3):
        pol_eval.loc[history_i[j]]['count']+=1
        
        if j < len(history_i):
            pol_eval.loc[history_i[j]]['sum']+= np.sum(np.array(history_i[j+2:len(history_i)-1:3]).astype(float))
            
        else :
            pol_eval.loc[history_i[j]['sum']] +=0
    
pol_eval.T

```


```{python,echo=TRUE}

pol_eval['sum']/pol_eval['count']

```

## Implementation 2 Pi^speed (runing estimate)

```{python, echo=TRUE}
pol_eval= pd.DataFrame(np.zeros(shape=(len(states),2)), index=states, columns=['count','est'])

pol_eval.T

new_info=0
for MC_i in range(len(history_speed)):
    history_i = history_speed[MC_i]
  
    for j in range(0, len(history_i),3):
        # update count
        pol_eval.loc[history_i[j]]['count']+=1
        current_cnt = pol_eval.loc[history_i[j]]['count']
        
        if j < len(history_i):
            new_info = np.sum(np.array(history_i[j+2:len(history_i)-1:3]).astype(float))
            
        else :
            new_info = 0
           
        alpha = 1/current_cnt
        pol_eval.loc[history_i[j]]['est']+=alpha*(new_info-pol_eval.loc[history_i[j]]['est'])
        
pol_eval
```


## Implementation 3 Pi^50 (vectorized)
```{python, echo=TRUE}
pol_eval= pd.DataFrame(np.zeros(shape=(len(states),2)), index=states, columns=['count','sum'])


for MC_i in range(len(history_speed)):
    history_i = history_50[MC_i]
    for j in range(0, len(history_i),3):
        pol_eval.loc[history_i[j]]['count']+=1
        
        if j < len(history_i):
            pol_eval.loc[history_i[j]]['sum']+= np.sum(np.array(history_i[j+2:len(history_i)-1:3]).astype(float))
            
        else :
            pol_eval.loc[history_i[j]['sum']] +=0
    
pol_eval.T    
```

```{python, echo=TRUE}
pol_eval['sum']/pol_eval['count']
```

## Implementation 4 Pi^50 (runing estimate)
```{python, echo=TRUE}
pol_eval= pd.DataFrame(np.zeros(shape=(len(states),2)), index=states, columns=['count','est'])

pol_eval.T

new_info=0
for MC_i in range(len(history_speed)):
    history_i = history_50[MC_i]
  
    for j in range(0, len(history_i),3):
        # update count
        pol_eval.loc[history_i[j]]['count']+=1
        current_cnt = pol_eval.loc[history_i[j]]['count']
        
        if j < len(history_i):
            new_info = np.sum(np.array(history_i[j+2:len(history_i)-1:3]).astype(float))
            
        else :
            new_info = 0
           
        alpha = 1/current_cnt
        pol_eval.loc[history_i[j]]['est']+=alpha*(new_info-pol_eval.loc[history_i[j]]['est'])
        
pol_eval
```


## implementation 5 - pi^speed with tempral diffrence
```{python, echo=TRUE}
pol_eval= pd.DataFrame(np.zeros(shape=(len(states),2)), index=states, columns=['count','est'])

pol_eval.T

new_info=0
for MC_i in range(len(history_speed)):
    history_i = history_speed[MC_i]
  
    for j in range(0, len(history_i),3):
        # update count
        pol_eval.loc[history_i[j]]['count']+=1
        current_cnt = pol_eval.loc[history_i[j]]['count']
        
        if j < len(history_i)-3:
            TD_target = np.array(history_i[j+2]).astype('float')+pol_eval.loc[history_i[j+3]]['est'] 
            
        else :
            TD_target = 0
           
        alpha = 1/current_cnt
        pol_eval.loc[history_i[j]]['est']+=alpha*(TD_target-pol_eval.loc[history_i[j]]['est'])
        
pol_eval

```


## implementation 6 - pi^50 with tempral diffrence
```{python, echo=TRUE}
pol_eval= pd.DataFrame(np.zeros(shape=(len(states),2)), index=states, columns=['count','est'])

pol_eval.T

new_info=0
for MC_i in range(len(history_speed)):
    history_i = history_50[MC_i]
  
    for j in range(0, len(history_i),3):
        # update count
        pol_eval.loc[history_i[j]]['count']+=1
        current_cnt = pol_eval.loc[history_i[j]]['count']
        
        if j < len(history_i)-3:
            TD_target = np.array(history_i[j+2]).astype('float')+pol_eval.loc[history_i[j+3]]['est'] 
            
        else :
            TD_target = 0
           
        alpha = 1/current_cnt
        pol_eval.loc[history_i[j]]['est']+=alpha*(TD_target-pol_eval.loc[history_i[j]]['est'])
        
pol_eval

```


```{r message=FALSE, warning=FALSE, paged.print=TRUE}
"Done "
```