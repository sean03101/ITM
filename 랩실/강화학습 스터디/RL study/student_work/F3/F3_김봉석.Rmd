---
title: "F3"  
author: "Bongseokkim"  
date: "`r Sys.Date()`"  
output:   
  pdf_document:  
    latex_engine: xelatex
    highlight: haddock  
    keep_tex: true  
    includes:
      in_header: rmd-pdf-support/latex-topmatter.tex
    # pandoc_args: [
    #  "-V", "classoption=twocolumn"
    # ]
    toc: true   
    toc_depth: 2  
    # number_sections: true  
monofont: Consolas
smaller: yes
classoption: a4paper
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(background = '718CBA')  
```

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
library(reticulate)
matplotlib <- import("matplotlib")
matplotlib$use("Agg", force = TRUE)
use_virtualenv("r-reticulate")
```


```{python , echo=FALSE}

import numpy as np
import pandas as pd
import time
#Model 
action_dict = {0:"n", 1:"s"}
Normal = 0
Speed = 1 

states = np.arange(0,80,10)

P_normal = np.array([[0, 1, 0, 0, 0, 0, 0, 0],
                     [0, 0, 1, 0, 0, 0, 0, 0],
                     [0, 0, 0, 1, 0, 0, 0, 0],
                     [0, 0, 0, 0, 1, 0, 0, 0],
                     [0, 0, 0, 0, 0, 1, 0, 0],
                     [0, 0, 0, 0, 0, 0, 1, 0],
                     [0, 0, 0, 0, 0, 0, 0, 1],
                     [0, 0, 0, 0, 0, 0, 0, 1]])

P_speed = np.array([[0.1, 0, 0.9, 0, 0, 0, 0, 0],
                    [0.1, 0, 0, 0.9, 0, 0, 0, 0],
                    [0, 0.1, 0, 0, 0.9, 0, 0, 0],
                    [0, 0, 0.1, 0, 0, 0.9, 0, 0],
                    [0, 0, 0, 0.1, 0, 0, 0.9, 0],
                    [0, 0, 0, 0, 0.1, 0, 0, 0.9],
                    [0, 0, 0, 0, 0, 0.1, 0, 0.9],
                    [0, 0, 0, 0, 0, 0, 0, 1]])

R_s_a = np.c_[[-1, -1, -1, -1, 0, -1, -1, 0], [-1.5, -1.5, -1.5, -1.5, -0.5, -1.5, -1.5, 0]]

q_s_a_init = np.c_[np.repeat( 0.0, len( states ) ), np.repeat( 0.0, len( states ) )]



pi_speed = np.c_[np.repeat( 0, len( states ) ), np.repeat( 1, len( states ) )]

pi_50  = np.c_[np.repeat( 0.5, len( states ) ), np.repeat( 0.5, len( states ) )]





def simul_path(pi, P_normal,P_speed, R_s_a):

    s_now = 0 
    history_i = [str(s_now)]
    while s_now != 70:
        if np.random.uniform() < pi[np.where(states == s_now),Normal] :
            a_now = Normal
            P = P_normal
        
        else :
            a_now = Speed 
            P = P_speed
        
        r_now = R_s_a[np.where(states == s_now)[0].item(),a_now]
        s_next = states[np.argmin(P[np.where(states == s_now),].cumsum() < np.random.uniform(0,1))] 
        history_i.extend([action_dict[a_now], r_now, str(s_next)])
        
        s_now = s_next
        
    return history_i
        
        
        
        





def simul_step(pi, s_now, P_normal, P_speed, R_s_a):
    
    if np.random.uniform() < pi[np.where(states == s_now),Normal]:
        a_now = Normal
        P = P_normal
    else:
        a_now = Speed
        P = P_speed

    r_now = R_s_a[np.where(states == s_now)[0].item(),a_now]
    s_next = states[np.argmin(P[np.where(states == s_now),].cumsum() < np.random.uniform(0,1))] 
    
    
    if np.random.uniform() < pi[np.where(states == s_next),Normal]:
        a_next = Normal
        
    else:
        a_next = Speed
        
    sarsa = [str(s_now), action_dict[a_now], r_now, str(s_next), action_dict[a_next]]
    return sarsa








def pol_eval_MC(sample_path, q_s_a, alpha):
    q_s_a_copy= q_s_a.copy()

    for j in range( 0,len( sample_path ) - 1, 3 ):
        s = sample_path[j]
        a = sample_path[j + 1]
        G = np.sum(np.array(sample_path[j + 2:len( sample_path )-1:3]).astype( float ) )
        
        q_s_a_copy[np.where(states== int(s)),list(action_dict.values()).index(a)] += alpha * (G - q_s_a_copy[np.where(states== int(s)),list(action_dict.values()).index(a)] )
    
    return q_s_a_copy










def pol_eval_TD(sample_step, q_s_a, alpha):
    q_s_a_copy= q_s_a.copy()
    s = sample_step[0]
    a = sample_step[1]
    r = sample_step[2]
    s_next = sample_step[3]
    a_next = sample_step[4]
    
    q_s_a_copy[np.where(states== int(s)),list(action_dict.values()).index(a)]     +=alpha*(r+q_s_a_copy[np.where(states== int(s_next)),list(action_dict.values()).index(a_next)]             -q_s_a_copy[np.where(states== int(s)),list(action_dict.values()).index(a)])
    
    return q_s_a_copy


def pol_imp(pi, q_s_a, epsilon): # epsilon = exploration_rate
    pi_copy =pi.copy()
    for i in range(pi.shape[0]):
        # exploitation
        if np.random.uniform() > epsilon:
            pi_copy[i] = 0
            pi_copy[i, np.argmax(q_s_a[i])] =1

        else:
            # exploration
            pi_copy[i] = 1/q_s_a.shape[1]
    return pi_copy


```


### Q_s_a Real
```{python, echo=TRUE}
real_solution =np.array([
  [-5.410774, -5.107744],
  [-4.441077, -4.410774],
  [-3.666667, -3.441077],
  [-2.666667, -3.344108],
  [-1.666667, -1.666667],
  [-2.000000, -1.666667],
  [-1.000000, -1.666667],
  [ 0.000000,  0.000000]] )

```


## Policy Iteration 1 -MC Control
```{python, echo=TRUE}
num_ep = 10**5
beg_time =time.time()
q_s_a = q_s_a_init
pi = pi_50
exploration_rate = 1

for epi_i in range(1,num_ep) :
    sample_path_i = simul_path(pi, P_normal, P_speed, R_s_a)
    q_s_a = pol_eval_MC(sample_path_i, q_s_a, alpha = 0.006 )
    pi = pol_imp(pi, q_s_a, exploration_rate)
    exploration_rate *=  0.989 # exponential decay

end_time =time.time()

result_q = pd.DataFrame(q_s_a, columns =['n','s'], index= states)
result_pi = pd.DataFrame(pi, columns =['n','s'], index= states)
print("Time difference of {} sec".format(end_time- beg_time))
print(result_pi.T)
print(result_q.T)
print("MSE :",((q_s_a-real_solution)**2).mean())

```


\newpage 

## Policy Iteration 2 - TD Control (a.k.a sarsa)
```{python, echo=TRUE}

num_ep = 10**5
beg_time =time.time()
q_s_a = q_s_a_init
pi = pi_50
exploration_rate = 1

for epi_i in range(1,num_ep) :
    s_now = 0
    while s_now != 70:
        sample_step = simul_step(pi,s_now, P_normal, P_speed, R_s_a)
        q_s_a = pol_eval_TD(sample_step, q_s_a, alpha = max(1/epi_i,0.01))
        pi = pol_imp(pi, q_s_a, epsilon=  exploration_rate)
        s_now = int(sample_step[3])
        exploration_rate *=0.9994

end_time =time.time()
result_q = pd.DataFrame(q_s_a, columns =['n','s'], index= states)
result_pi = pd.DataFrame(pi, columns =['n','s'], index= states)
print("Time difference of {} sec".format(end_time- beg_time))
print(result_pi.T)
print(result_q.T)
print("MSE :",((q_s_a-real_solution)**2).mean())
```


```{python, echo=TRUE}


```


```{python, echo=TRUE}


```


```{python, echo=TRUE}


```





```{r message=FALSE, warning=FALSE, paged.print=TRUE}
"Done "
```