{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vFXgflvZ6Ga"
      },
      "source": [
        "## Assignment #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UevAU0CYVhiu"
      },
      "source": [
        "* Release date: 2021.10.12 Tue\n",
        "* Due date: **2021.10.19 Tue 23:59** (will not accept late submission)\n",
        "* Submission format: notebook file which can be executed in Colab environment\n",
        "* Weighting: 5% (total 50 pts)\n",
        "* You will build a multi-class classification model using Reuters dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxrhNNhWbfHD"
      },
      "source": [
        "> ### Loading and preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E-2WLHgcAit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cef9edc-793a-415b-b1ae-a03db7624d24"
      },
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "# Like IMDB, the argument num_words restricts the data to \n",
        "# the 10,000 most frequently occurring words \n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n",
            "2121728/2110848 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3EivNEoEKTF"
      },
      "source": [
        "* (10pts) Write the codes for preprocessing data\n",
        "  * For inputs, the data we have should be converted to binary vectors.\n",
        "  * For labels, determine an appropriate format by referring to the arguments of model.compile function below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrjD9AerdW4X"
      },
      "source": [
        "# write preprocessing codes\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    #Create a matrix with size (sequences, dimension) and all elements zero.\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1. # Make the location of a specific index 1 in results[i].\n",
        "    return results\n",
        "\n",
        "train_data = vectorize_sequences(train_data) # Convert training data into vectors.\n",
        "test_data = vectorize_sequences(test_data) # Convert test data into vectors.\n",
        "\n",
        "train_labels = np.asarray(train_labels).astype('float32')\n",
        "test_labels = np.asarray(test_labels).astype('float32')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWfgUJiPeicE"
      },
      "source": [
        "> ### Building the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edwc4GbneqKA"
      },
      "source": [
        "# Do not modify this block\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxGWsKkdgAnq"
      },
      "source": [
        "# Do not modify this block\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0TUwiHLgI_-"
      },
      "source": [
        "> ### Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFe4FOkfgUII"
      },
      "source": [
        "* We employ *k-fold cross validation* as validation method of our model.\n",
        "* **(15pts)** Write a code in the below to perform *10-fold cross validation*.\n",
        "* **For each fold, save a model at every epoch in your Google Drive.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPWjg2s4WYfm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c16cb3c-6f77-4530-927c-c8f4bca76a4b"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "def get_model_name(k):\n",
        "    return '/{epoch:d}/K-fold_'+str(k)+'.h5'\n",
        "\n",
        "k = 10\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 15\n",
        "\n",
        "train_acc_history = []\n",
        "val_acc_history = []\n",
        "\n",
        "save_dir = '/content/saved_models/'\n",
        "s = np.arange(train_data.shape[0])\n",
        "\n",
        "train_data = train_data[s]\n",
        "train_labels = train_labels[s]\n",
        "\n",
        "for i in range(k):\n",
        "\n",
        "  print('processing fold #', i+1)\n",
        "  val_data = train_data[i*num_val_samples: (i+1)*num_val_samples]\n",
        "  val_targets = train_labels[i*num_val_samples: (i+1)*num_val_samples]\n",
        "  \n",
        "  partial_train_data = np.concatenate([train_data[:i*num_val_samples],\n",
        "                                       train_data[(i+1)*num_val_samples:]],\n",
        "                                      axis=0)\n",
        "  partial_train_targets = np.concatenate([train_labels[:i*num_val_samples],\n",
        "                                          train_labels[(i+1)*num_val_samples:]],\n",
        "                                         axis=0)\n",
        "    \n",
        "  model_temp = model\n",
        "  checkpointer = ModelCheckpoint(filepath=save_dir+get_model_name(i+1), verbose=0, monitor='val_loss', save_weights_only=False, save_best_only=False, mode='auto', save_freq='epoch') \n",
        "\n",
        "  history = model_temp.fit(partial_train_data, \n",
        "                      partial_train_targets,\n",
        "                      validation_data=(val_data, val_targets),\n",
        "                      epochs=num_epochs,\n",
        "                      batch_size=20,\n",
        "                      callbacks=[checkpointer])\n",
        "\n",
        "  train_acc_history.append(history.history['accuracy'])\n",
        "  val_acc_history.append(history.history['val_accuracy'])\n",
        " \n",
        " \n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing fold # 1\n",
            "Epoch 1/15\n",
            "405/405 [==============================] - 5s 10ms/step - loss: 1.3689 - accuracy: 0.7023 - val_loss: 1.0371 - val_accuracy: 0.7851\n",
            "Epoch 2/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.7302 - accuracy: 0.8402 - val_loss: 0.9248 - val_accuracy: 0.8140\n",
            "Epoch 3/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.4741 - accuracy: 0.8986 - val_loss: 0.9209 - val_accuracy: 0.8185\n",
            "Epoch 4/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.3383 - accuracy: 0.9240 - val_loss: 0.9768 - val_accuracy: 0.8174\n",
            "Epoch 5/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.2632 - accuracy: 0.9400 - val_loss: 1.0783 - val_accuracy: 0.8140\n",
            "Epoch 6/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.2279 - accuracy: 0.9487 - val_loss: 1.1382 - val_accuracy: 0.8096\n",
            "Epoch 7/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1972 - accuracy: 0.9539 - val_loss: 1.3631 - val_accuracy: 0.8096\n",
            "Epoch 8/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1784 - accuracy: 0.9545 - val_loss: 1.2050 - val_accuracy: 0.8096\n",
            "Epoch 9/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1752 - accuracy: 0.9557 - val_loss: 1.3884 - val_accuracy: 0.7973\n",
            "Epoch 10/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1679 - accuracy: 0.9571 - val_loss: 1.5980 - val_accuracy: 0.7973\n",
            "Epoch 11/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1623 - accuracy: 0.9563 - val_loss: 1.4863 - val_accuracy: 0.8029\n",
            "Epoch 12/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1537 - accuracy: 0.9571 - val_loss: 1.5670 - val_accuracy: 0.7795\n",
            "Epoch 13/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1497 - accuracy: 0.9571 - val_loss: 1.7734 - val_accuracy: 0.7895\n",
            "Epoch 14/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1466 - accuracy: 0.9573 - val_loss: 1.8641 - val_accuracy: 0.7973\n",
            "Epoch 15/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1444 - accuracy: 0.9577 - val_loss: 1.7539 - val_accuracy: 0.7929\n",
            "processing fold # 2\n",
            "Epoch 1/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.2802 - accuracy: 0.9398 - val_loss: 0.1769 - val_accuracy: 0.9510\n",
            "Epoch 2/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1959 - accuracy: 0.9506 - val_loss: 0.2275 - val_accuracy: 0.9521\n",
            "Epoch 3/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1647 - accuracy: 0.9531 - val_loss: 0.2750 - val_accuracy: 0.9432\n",
            "Epoch 4/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1511 - accuracy: 0.9553 - val_loss: 0.3671 - val_accuracy: 0.9443\n",
            "Epoch 5/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1434 - accuracy: 0.9571 - val_loss: 0.3508 - val_accuracy: 0.9410\n",
            "Epoch 6/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1375 - accuracy: 0.9563 - val_loss: 0.4131 - val_accuracy: 0.9332\n",
            "Epoch 7/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1349 - accuracy: 0.9589 - val_loss: 0.4654 - val_accuracy: 0.9343\n",
            "Epoch 8/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1316 - accuracy: 0.9589 - val_loss: 0.5248 - val_accuracy: 0.9332\n",
            "Epoch 9/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1315 - accuracy: 0.9574 - val_loss: 0.5333 - val_accuracy: 0.9287\n",
            "Epoch 10/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1262 - accuracy: 0.9600 - val_loss: 0.6455 - val_accuracy: 0.9287\n",
            "Epoch 11/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1296 - accuracy: 0.9589 - val_loss: 0.6990 - val_accuracy: 0.9187\n",
            "Epoch 12/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1295 - accuracy: 0.9602 - val_loss: 0.7236 - val_accuracy: 0.9131\n",
            "Epoch 13/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1272 - accuracy: 0.9593 - val_loss: 0.8167 - val_accuracy: 0.9165\n",
            "Epoch 14/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1219 - accuracy: 0.9597 - val_loss: 0.9370 - val_accuracy: 0.9109\n",
            "Epoch 15/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1264 - accuracy: 0.9595 - val_loss: 0.9437 - val_accuracy: 0.9076\n",
            "processing fold # 3\n",
            "Epoch 1/15\n",
            "405/405 [==============================] - 3s 9ms/step - loss: 0.1947 - accuracy: 0.9531 - val_loss: 0.1307 - val_accuracy: 0.9588\n",
            "Epoch 2/15\n",
            "405/405 [==============================] - 3s 8ms/step - loss: 0.1460 - accuracy: 0.9594 - val_loss: 0.2306 - val_accuracy: 0.9454\n",
            "Epoch 3/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1392 - accuracy: 0.9586 - val_loss: 0.2615 - val_accuracy: 0.9488\n",
            "Epoch 4/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1350 - accuracy: 0.9603 - val_loss: 0.3616 - val_accuracy: 0.9354\n",
            "Epoch 5/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1295 - accuracy: 0.9610 - val_loss: 0.4101 - val_accuracy: 0.9365\n",
            "Epoch 6/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1277 - accuracy: 0.9587 - val_loss: 0.4777 - val_accuracy: 0.9321\n",
            "Epoch 7/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1227 - accuracy: 0.9599 - val_loss: 0.5194 - val_accuracy: 0.9287\n",
            "Epoch 8/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1243 - accuracy: 0.9619 - val_loss: 0.5982 - val_accuracy: 0.9365\n",
            "Epoch 9/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1260 - accuracy: 0.9593 - val_loss: 0.8188 - val_accuracy: 0.9254\n",
            "Epoch 10/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1205 - accuracy: 0.9618 - val_loss: 0.7564 - val_accuracy: 0.9220\n",
            "Epoch 11/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1158 - accuracy: 0.9619 - val_loss: 0.7521 - val_accuracy: 0.9220\n",
            "Epoch 12/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1209 - accuracy: 0.9598 - val_loss: 1.0995 - val_accuracy: 0.9209\n",
            "Epoch 13/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1157 - accuracy: 0.9604 - val_loss: 0.9174 - val_accuracy: 0.9165\n",
            "Epoch 14/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1154 - accuracy: 0.9610 - val_loss: 1.1190 - val_accuracy: 0.9187\n",
            "Epoch 15/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1169 - accuracy: 0.9617 - val_loss: 1.0776 - val_accuracy: 0.9154\n",
            "processing fold # 4\n",
            "Epoch 1/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.2106 - accuracy: 0.9556 - val_loss: 0.1026 - val_accuracy: 0.9566\n",
            "Epoch 2/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1697 - accuracy: 0.9588 - val_loss: 0.1575 - val_accuracy: 0.9465\n",
            "Epoch 3/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1391 - accuracy: 0.9605 - val_loss: 0.2187 - val_accuracy: 0.9432\n",
            "Epoch 4/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1423 - accuracy: 0.9605 - val_loss: 0.2894 - val_accuracy: 0.9421\n",
            "Epoch 5/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1252 - accuracy: 0.9631 - val_loss: 0.3133 - val_accuracy: 0.9354\n",
            "Epoch 6/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1309 - accuracy: 0.9623 - val_loss: 0.3846 - val_accuracy: 0.9388\n",
            "Epoch 7/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1264 - accuracy: 0.9612 - val_loss: 0.4537 - val_accuracy: 0.9265\n",
            "Epoch 8/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1213 - accuracy: 0.9615 - val_loss: 0.5380 - val_accuracy: 0.9310\n",
            "Epoch 9/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1314 - accuracy: 0.9613 - val_loss: 0.5148 - val_accuracy: 0.9265\n",
            "Epoch 10/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1202 - accuracy: 0.9638 - val_loss: 0.5645 - val_accuracy: 0.9343\n",
            "Epoch 11/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1154 - accuracy: 0.9633 - val_loss: 0.7358 - val_accuracy: 0.9254\n",
            "Epoch 12/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1230 - accuracy: 0.9628 - val_loss: 0.7944 - val_accuracy: 0.9131\n",
            "Epoch 13/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1211 - accuracy: 0.9625 - val_loss: 0.7980 - val_accuracy: 0.9165\n",
            "Epoch 14/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1157 - accuracy: 0.9617 - val_loss: 0.8237 - val_accuracy: 0.9020\n",
            "Epoch 15/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1120 - accuracy: 0.9629 - val_loss: 0.9122 - val_accuracy: 0.9120\n",
            "processing fold # 5\n",
            "Epoch 1/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.2072 - accuracy: 0.9595 - val_loss: 0.1656 - val_accuracy: 0.9488\n",
            "Epoch 2/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1441 - accuracy: 0.9610 - val_loss: 0.2885 - val_accuracy: 0.9477\n",
            "Epoch 3/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1477 - accuracy: 0.9612 - val_loss: 0.2526 - val_accuracy: 0.9421\n",
            "Epoch 4/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1377 - accuracy: 0.9635 - val_loss: 0.3754 - val_accuracy: 0.9454\n",
            "Epoch 5/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1282 - accuracy: 0.9604 - val_loss: 0.4650 - val_accuracy: 0.9376\n",
            "Epoch 6/15\n",
            "405/405 [==============================] - 3s 8ms/step - loss: 0.1195 - accuracy: 0.9613 - val_loss: 0.5073 - val_accuracy: 0.9376\n",
            "Epoch 7/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1229 - accuracy: 0.9634 - val_loss: 0.4912 - val_accuracy: 0.9321\n",
            "Epoch 8/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1117 - accuracy: 0.9610 - val_loss: 0.7167 - val_accuracy: 0.9365\n",
            "Epoch 9/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1161 - accuracy: 0.9620 - val_loss: 0.7279 - val_accuracy: 0.9321\n",
            "Epoch 10/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1173 - accuracy: 0.9615 - val_loss: 0.8613 - val_accuracy: 0.9265\n",
            "Epoch 11/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1042 - accuracy: 0.9630 - val_loss: 1.1721 - val_accuracy: 0.9287\n",
            "Epoch 12/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1302 - accuracy: 0.9605 - val_loss: 0.9857 - val_accuracy: 0.9209\n",
            "Epoch 13/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1073 - accuracy: 0.9644 - val_loss: 1.3817 - val_accuracy: 0.9143\n",
            "Epoch 14/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1055 - accuracy: 0.9629 - val_loss: 1.1523 - val_accuracy: 0.9165\n",
            "Epoch 15/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1166 - accuracy: 0.9610 - val_loss: 1.2231 - val_accuracy: 0.9176\n",
            "processing fold # 6\n",
            "Epoch 1/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.2599 - accuracy: 0.9556 - val_loss: 0.0742 - val_accuracy: 0.9677\n",
            "Epoch 2/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1791 - accuracy: 0.9570 - val_loss: 0.1104 - val_accuracy: 0.9666\n",
            "Epoch 3/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1585 - accuracy: 0.9592 - val_loss: 0.1602 - val_accuracy: 0.9633\n",
            "Epoch 4/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1572 - accuracy: 0.9598 - val_loss: 0.1648 - val_accuracy: 0.9621\n",
            "Epoch 5/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1466 - accuracy: 0.9595 - val_loss: 0.2075 - val_accuracy: 0.9566\n",
            "Epoch 6/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1476 - accuracy: 0.9603 - val_loss: 0.2564 - val_accuracy: 0.9532\n",
            "Epoch 7/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1436 - accuracy: 0.9599 - val_loss: 0.3101 - val_accuracy: 0.9510\n",
            "Epoch 8/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1288 - accuracy: 0.9612 - val_loss: 0.4400 - val_accuracy: 0.9510\n",
            "Epoch 9/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1140 - accuracy: 0.9588 - val_loss: 0.7269 - val_accuracy: 0.9521\n",
            "Epoch 10/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1388 - accuracy: 0.9618 - val_loss: 0.6573 - val_accuracy: 0.9499\n",
            "Epoch 11/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1226 - accuracy: 0.9600 - val_loss: 0.7545 - val_accuracy: 0.9465\n",
            "Epoch 12/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1368 - accuracy: 0.9589 - val_loss: 0.5759 - val_accuracy: 0.9454\n",
            "Epoch 13/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1247 - accuracy: 0.9619 - val_loss: 0.8827 - val_accuracy: 0.9376\n",
            "Epoch 14/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1363 - accuracy: 0.9610 - val_loss: 0.8874 - val_accuracy: 0.9265\n",
            "Epoch 15/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1249 - accuracy: 0.9608 - val_loss: 1.0032 - val_accuracy: 0.9421\n",
            "processing fold # 7\n",
            "Epoch 1/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.2081 - accuracy: 0.9577 - val_loss: 0.1491 - val_accuracy: 0.9655\n",
            "Epoch 2/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1586 - accuracy: 0.9603 - val_loss: 0.1379 - val_accuracy: 0.9610\n",
            "Epoch 3/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1341 - accuracy: 0.9600 - val_loss: 0.1651 - val_accuracy: 0.9610\n",
            "Epoch 4/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1528 - accuracy: 0.9594 - val_loss: 0.2150 - val_accuracy: 0.9577\n",
            "Epoch 5/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1260 - accuracy: 0.9589 - val_loss: 0.2641 - val_accuracy: 0.9532\n",
            "Epoch 6/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1191 - accuracy: 0.9618 - val_loss: 0.2468 - val_accuracy: 0.9532\n",
            "Epoch 7/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1306 - accuracy: 0.9600 - val_loss: 0.3179 - val_accuracy: 0.9532\n",
            "Epoch 8/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1168 - accuracy: 0.9623 - val_loss: 0.4561 - val_accuracy: 0.9521\n",
            "Epoch 9/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1205 - accuracy: 0.9604 - val_loss: 0.4775 - val_accuracy: 0.9532\n",
            "Epoch 10/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1177 - accuracy: 0.9591 - val_loss: 0.4879 - val_accuracy: 0.9465\n",
            "Epoch 11/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1242 - accuracy: 0.9624 - val_loss: 0.4951 - val_accuracy: 0.9410\n",
            "Epoch 12/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1081 - accuracy: 0.9625 - val_loss: 0.5473 - val_accuracy: 0.9443\n",
            "Epoch 13/15\n",
            "405/405 [==============================] - 6s 15ms/step - loss: 0.1151 - accuracy: 0.9598 - val_loss: 0.6363 - val_accuracy: 0.9432\n",
            "Epoch 14/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1577 - accuracy: 0.9617 - val_loss: 0.5399 - val_accuracy: 0.9365\n",
            "Epoch 15/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1121 - accuracy: 0.9608 - val_loss: 0.6554 - val_accuracy: 0.9399\n",
            "processing fold # 8\n",
            "Epoch 1/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1664 - accuracy: 0.9612 - val_loss: 0.1037 - val_accuracy: 0.9499\n",
            "Epoch 2/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1440 - accuracy: 0.9635 - val_loss: 0.2044 - val_accuracy: 0.9376\n",
            "Epoch 3/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1287 - accuracy: 0.9628 - val_loss: 0.2127 - val_accuracy: 0.9354\n",
            "Epoch 4/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1336 - accuracy: 0.9621 - val_loss: 0.2082 - val_accuracy: 0.9376\n",
            "Epoch 5/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1252 - accuracy: 0.9643 - val_loss: 0.3078 - val_accuracy: 0.9310\n",
            "Epoch 6/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1183 - accuracy: 0.9651 - val_loss: 0.3440 - val_accuracy: 0.9287\n",
            "Epoch 7/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1235 - accuracy: 0.9641 - val_loss: 0.4529 - val_accuracy: 0.9254\n",
            "Epoch 8/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1406 - accuracy: 0.9652 - val_loss: 0.4037 - val_accuracy: 0.9276\n",
            "Epoch 9/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1170 - accuracy: 0.9631 - val_loss: 0.5059 - val_accuracy: 0.9232\n",
            "Epoch 10/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1285 - accuracy: 0.9636 - val_loss: 0.4470 - val_accuracy: 0.9276\n",
            "Epoch 11/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1515 - accuracy: 0.9640 - val_loss: 0.4529 - val_accuracy: 0.9220\n",
            "Epoch 12/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1190 - accuracy: 0.9643 - val_loss: 0.4791 - val_accuracy: 0.9265\n",
            "Epoch 13/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1285 - accuracy: 0.9654 - val_loss: 0.5028 - val_accuracy: 0.9209\n",
            "Epoch 14/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1031 - accuracy: 0.9645 - val_loss: 0.6177 - val_accuracy: 0.9198\n",
            "Epoch 15/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1074 - accuracy: 0.9650 - val_loss: 0.7429 - val_accuracy: 0.9220\n",
            "processing fold # 9\n",
            "Epoch 1/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1771 - accuracy: 0.9592 - val_loss: 0.1128 - val_accuracy: 0.9666\n",
            "Epoch 2/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1678 - accuracy: 0.9603 - val_loss: 0.1281 - val_accuracy: 0.9633\n",
            "Epoch 3/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1462 - accuracy: 0.9598 - val_loss: 0.1420 - val_accuracy: 0.9599\n",
            "Epoch 4/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1674 - accuracy: 0.9618 - val_loss: 0.1843 - val_accuracy: 0.9521\n",
            "Epoch 5/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1285 - accuracy: 0.9630 - val_loss: 0.2322 - val_accuracy: 0.9521\n",
            "Epoch 6/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1287 - accuracy: 0.9623 - val_loss: 0.2505 - val_accuracy: 0.9577\n",
            "Epoch 7/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1187 - accuracy: 0.9618 - val_loss: 0.2745 - val_accuracy: 0.9510\n",
            "Epoch 8/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1241 - accuracy: 0.9628 - val_loss: 0.3827 - val_accuracy: 0.9488\n",
            "Epoch 9/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1261 - accuracy: 0.9640 - val_loss: 0.3610 - val_accuracy: 0.9432\n",
            "Epoch 10/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1480 - accuracy: 0.9633 - val_loss: 0.4310 - val_accuracy: 0.9376\n",
            "Epoch 11/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1206 - accuracy: 0.9620 - val_loss: 0.4407 - val_accuracy: 0.9399\n",
            "Epoch 12/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1243 - accuracy: 0.9628 - val_loss: 0.5236 - val_accuracy: 0.9365\n",
            "Epoch 13/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1214 - accuracy: 0.9650 - val_loss: 0.4674 - val_accuracy: 0.9410\n",
            "Epoch 14/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1234 - accuracy: 0.9640 - val_loss: 0.5207 - val_accuracy: 0.9365\n",
            "Epoch 15/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1192 - accuracy: 0.9638 - val_loss: 0.6473 - val_accuracy: 0.9354\n",
            "processing fold # 10\n",
            "Epoch 1/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1963 - accuracy: 0.9584 - val_loss: 0.1161 - val_accuracy: 0.9644\n",
            "Epoch 2/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1303 - accuracy: 0.9635 - val_loss: 0.1967 - val_accuracy: 0.9555\n",
            "Epoch 3/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1336 - accuracy: 0.9613 - val_loss: 0.2260 - val_accuracy: 0.9499\n",
            "Epoch 4/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1406 - accuracy: 0.9624 - val_loss: 0.2152 - val_accuracy: 0.9532\n",
            "Epoch 5/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1243 - accuracy: 0.9626 - val_loss: 0.3200 - val_accuracy: 0.9454\n",
            "Epoch 6/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1247 - accuracy: 0.9612 - val_loss: 0.3811 - val_accuracy: 0.9421\n",
            "Epoch 7/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1077 - accuracy: 0.9626 - val_loss: 0.3976 - val_accuracy: 0.9388\n",
            "Epoch 8/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1159 - accuracy: 0.9629 - val_loss: 0.4608 - val_accuracy: 0.9399\n",
            "Epoch 9/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1134 - accuracy: 0.9617 - val_loss: 0.4754 - val_accuracy: 0.9454\n",
            "Epoch 10/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1259 - accuracy: 0.9623 - val_loss: 0.5427 - val_accuracy: 0.9376\n",
            "Epoch 11/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1100 - accuracy: 0.9636 - val_loss: 0.5940 - val_accuracy: 0.9354\n",
            "Epoch 12/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1335 - accuracy: 0.9629 - val_loss: 0.6321 - val_accuracy: 0.9354\n",
            "Epoch 13/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1063 - accuracy: 0.9638 - val_loss: 0.6212 - val_accuracy: 0.9354\n",
            "Epoch 14/15\n",
            "405/405 [==============================] - 4s 9ms/step - loss: 0.1158 - accuracy: 0.9665 - val_loss: 0.7723 - val_accuracy: 0.9354\n",
            "Epoch 15/15\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1253 - accuracy: 0.9629 - val_loss: 0.6349 - val_accuracy: 0.9310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8908muCWdnG"
      },
      "source": [
        "* **(10pts)** Plotting the training and validation accuracy\n",
        "  * To obtain the validation accuracy at the end of every epoch, just average the performances of all folds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PJb3RyXXZlC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "ee89a67a-0581-44b2-94b6-1e3fe85b187c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "avg_epoch_train = [np.mean([x[i] for x in train_acc_history]) for i in range(num_epochs)]\n",
        "avg_epoch_val = [np.mean([x[i] for x in val_acc_history]) for i in range(num_epochs)]\n",
        "\n",
        "max_point = avg_epoch_val.index(max(avg_epoch_val))+1\n",
        "  \n",
        "epoch_list = []\n",
        "for i in range(num_epochs):\n",
        "  epoch_list.append(i+1)\n",
        "\n",
        "plt.plot(epoch_list, avg_epoch_train, 'bo', label='Train accuracy avg')\n",
        "plt.plot(epoch_list, avg_epoch_val, 'ro', label='Val accuracy avg')\n",
        "\n",
        "plt.title('Each epochs validation accuracy avg')\n",
        "plt.xlabel('Epochs') \n",
        "plt.ylabel('Avg of 10-fold acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"Val accuracy's max epoch point : \",max_point)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val accuracy's max epoch point :  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9HNF524XkCy"
      },
      "source": [
        "* Find the best performance model by seeing the performance plot.\n",
        "* Calculate the accuracy on test set using the best performance model.\n",
        "  * Here, you should use a majority voting method to get the prediction for a test data point.\n",
        "  * Specifically, given a test data point, get the predicted class from the trained model on each fold, and then decide the final predicted class by a majority voting.\n",
        "* **Do not retrain the model.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS0D5_0iXd_y"
      },
      "source": [
        "> ### (15pts) Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nd7FlEG30hQ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhDWsnWuY5w-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d12b8d2-d630-48e1-d501-64e830ea43c5"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "col_list = []\n",
        "for i in range(len(test_labels)):\n",
        "  col_list.append(i+1)\n",
        "\n",
        "df = pd.DataFrame(columns=col_list)\n",
        "\n",
        "for i in range(10):\n",
        "  new_model = model\n",
        "  new_model.load_weights(\"/content/saved_models/\"+ str(max_point) +\"/K-fold_\"+str(i+1)+\".h5\")\n",
        "  outcomes  = np.argmax(new_model.predict(test_data), axis=1)\n",
        "  df.loc[i] = outcomes\n",
        "\n",
        "# Hard voting\n",
        "temp = df.mode()  \n",
        "ensemble_labels = np.array(temp.loc[0].tolist())\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Majority voting model's score is\", round(accuracy_score(test_labels, ensemble_labels),4))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Majority voting model's score is 0.7587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sN0I41vOFz9",
        "outputId": "6eb3c1f3-28b9-455e-ca16-6283c22258e2"
      },
      "source": [
        "'''\n",
        "models_list = []\n",
        "\n",
        "for i in range(10):\n",
        "  new_model = model\n",
        "  new_model.load_weights(\"/content/saved_models/\"+ str(max_point) +\"/K-fold_\"+str(i+1)+\".h5\")\n",
        "  models_list.append(new_model) \n",
        "\n",
        "# make predictions\n",
        "yhats = [model_temp.predict(test_data) for model_temp in models_list]\n",
        "# sum across ensembles\n",
        "summed = np.sum(yhats, axis=0)\n",
        "# argmax across classes\n",
        "outcomes = np.argmax(summed, axis=1)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Soft voting model's score is\", round(accuracy_score(test_labels, outcomes),4))\n",
        "'''"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Soft voting model's score is 0.6821\n"
          ]
        }
      ]
    }
  ]
}